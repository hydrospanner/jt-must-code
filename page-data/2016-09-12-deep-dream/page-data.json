{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/2016-09-12-deep-dream/",
    "result": {"data":{"site":{"siteMetadata":{"title":"John Tucker Must Code"}},"markdownRemark":{"id":"eab5fe35-a0be-544a-8947-1ad0db32b807","excerpt":"Google’s Deep Dream enhances patterns in an image similar to the way your mind perceives a face in the moon, an algorithmic pareidolia. I recently found a…","html":"<div classname=\"Image__Medium\">\n  <img src=\"/b2ff56885ca0bc22d2f91a731b8c49c2/deep_dream_iterations.gif\" alt=\"This GIF shows how the number of Deep Dream iterations affects the image.\">\n</div>\n<p>Google’s Deep Dream enhances patterns in an image similar to the way your mind perceives a face in the moon, an algorithmic pareidolia. I recently found a Jupyter Notebook, published by Google, showing how to produce the Deep Dream visuals. I thought I’d give it a shot.</p>\n<p>If you have never heard of Deep Dream, this GIF shows its effect on an image.\nThis GIF shows how the number of Deep Dream iterations affects the image.</p>\n<p>GitHub is not able to show two of the GIFs I created in my notebook due to file size limitations. I included them in this blog post (one I converted to video).</p>\n<div class=\"gatsby-resp-iframe-wrapper\" style=\"padding-bottom: 56.25%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem\" > <iframe src=\"https://www.youtube.com/embed/geEyYqqpHKs\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\" style=\" position: absolute; top: 0; left: 0; width: 100%; height: 100%; \"></iframe> </div>\n<p>This video was made by applying the Deep Dream filter, zooming in, and looping that 200 times. There are some noticeable differences between this video and the <a href=\"https://github.com/hydrospanner/Deep-Dream/blob/master/img%20loops/zoomgif.gif\">original GIF</a>.</p>\n<p><a href=\"https://nbviewer.jupyter.org/github/hydrospanner/Deep-Dream/blob/master/deep%20dream.ipynb\">Here’s how I used the Deep Dream program.</a></p>\n<p>I’m happy with how it turned out. I was able to see the capabilities of Deep Dream by iterating through various settings. I was able to use Python to turn the generated images into labeled GIFs and tiled images. I think it turned out to be an effective way to display the data.</p>\n<h3>Installation</h3>\n<p>This Notebook uses Python Imaging Library (PIL) which has yet to release a version for Python 3.X, so I’ll need to run the notebook on Python 2.7. Good thing Anaconda makes managing different Python environments easy. I wonder why Google didn’t use Pillow instead and run the project on Python 3.</p>\n<p>Installing Caffe was more difficult than I expected. Some issues I came across are:</p>\n<ul>\n<li>Instead of using a package manager, Caffe needs to be built with Visual Studio.</li>\n<li>There are multiple versions of Caffe for Windows available on GitHub. The two I tried were from Berkeley Vision and Learning Center (BVLC) and Microsoft.\n<ul>\n<li>When I tried to build Microsoft’s Caffe, the build failed. This was due to the build requiring a debug version of Python. Oddly the installation instructions made no mention of this requirement. It’s only mentioned in the .PROPS file where the build’s variables are set.</li>\n<li>I was able to build the BVLC version of Caffe, even though it mentioned the same debug requirement in the .PROPS file.</li>\n</ul>\n</li>\n</ul>\n<p>The Microsoft Surface I’m running this on has an integrated GPU, which does not support NVIDIA’s CUDA. I had to use a CpuBuildOnly build. At default settings it took about 5 minutes to render an image using most filters. I would look into a GPU build for a larger project.</p>\n<p><a href=\"https://github.com/hydrospanner/Deep-Dream\">Source for this project</a></p>\n<p>For more Deep Dreams, see <a href=\"https://www.instagram.com/deepdreamgenerator/\">this Instagram</a>.</p>","frontmatter":{"title":"Google's Deep Dream","date":"September 12, 2016","description":"Getting weird with deep learning image processing"}},"previous":{"fields":{"slug":"/2015-12-15-asteriods/"},"frontmatter":{"title":"Asteriods"}},"next":{"fields":{"slug":"/2017-02-17-crossover-trading/"},"frontmatter":{"title":"Cross Over Stock Trading Algorithm"}}},"pageContext":{"id":"eab5fe35-a0be-544a-8947-1ad0db32b807","previousPostId":"aa381162-7db0-5b3b-ab79-6c0951443ee4","nextPostId":"009a9ec8-b839-50fb-a1e0-ce6b8c668e9f"}},
    "staticQueryHashes": ["1804815106","2841359383"]}